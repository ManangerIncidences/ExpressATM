"""
üîó Scheduler H√≠brido - ExpressATM
Scheduler que soporta tanto el sistema cl√°sico como el inteligente
Permite migraci√≥n gradual y comparaci√≥n de rendimiento
"""

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from datetime import datetime, date, timedelta
import logging
import time
import psutil
from .scraper import LotteryMonitorScraper
from .alerts import AlertSystem
from .database import SessionLocal
from .models import MonitoringSession, SystemLog
from backend.config import Config
from .dom_learning_engine import dom_learner

# üß† Importar sistema inteligente
try:
    from .scraper_intelligent import IntelligentLotteryMonitorScraper  # type: ignore
    from .intelligence import intelligence_engine  # type: ignore
    from .dom_intelligence import dom_intelligence  # type: ignore
    INTELLIGENT_SYSTEM_AVAILABLE = True
    print("Sistema inteligente disponible")
except ImportError as e:
    INTELLIGENT_SYSTEM_AVAILABLE = False
    print(f"Sistema inteligente no disponible: {e}")

logger = logging.getLogger(__name__)

class HybridMonitoringScheduler:
    """Scheduler h√≠brido que soporta migraci√≥n gradual"""
    
    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.is_running = False
        self.current_session_id = None
        
        # Configuraci√≥n de migraci√≥n
        self.use_intelligent_system = False  # Flag principal
        self.intelligent_percentage = 0     # Porcentaje de ejecuciones con IA
        self.comparison_mode = False        # Ejecutar ambos y comparar
        
        # ÔøΩ MODO CONTINUO PARA PRUEBAS
        self.continuous_mode = False        # Modo de ejecuci√≥n continua
        self.continuous_delay = 10          # Segundos entre ejecuciones continuas
        
        # ÔøΩüîß INICIALIZACI√ìN LAZY DE SCRAPERS (solo cuando se necesiten)
        self._classic_scraper = None
        self._intelligent_scraper = None
        
        # Sistema de alertas
        self.alert_system = AlertSystem()
        
        # M√©tricas de comparaci√≥n
        self.performance_metrics = {
            'classic': {'count': 0, 'total_time': 0, 'errors': 0},
            'intelligent': {'count': 0, 'total_time': 0, 'errors': 0}
        }
        
        self.intelligence_enabled = False
        # === Estado de progreso (similar al scheduler cl√°sico) ===
        import threading
        self._progress_lock = threading.Lock()
        self._progress = {"active": False, "steps": []}

        logger.info("Scheduler hibrido inicializado (scrapers lazy)")

    # ====== Gesti√≥n de progreso ======
    def _now_iso(self):
        from datetime import datetime as _dt
        return _dt.utcnow().isoformat()

    def _progress_steps_template(self):
        return [
            {"key": "login", "label": "Login", "status": "pending"},
            {"key": "navigate", "label": "Navegaci√≥n", "status": "pending"},
            {"key": "base_filters", "label": "Filtros base", "status": "pending"},
            {"key": "chance", "label": "CHANCE EXPRESS", "status": "pending"},
            {"key": "ruleta", "label": "RULETA EXPRESS", "status": "pending"},
            {"key": "data_ready", "label": "Datos listos", "status": "pending"},
            {"key": "generate_alerts", "label": "Generando alertas", "status": "pending"},
            {"key": "complete", "label": "Completado", "status": "pending"}
        ]

    def _start_progress(self):
        with self._progress_lock:
            self._progress = {
                "active": True,
                "started_at": self._now_iso(),
                "updated_at": self._now_iso(),
                "version": 1,
                "steps": self._progress_steps_template(),
                "current": None,
                "error": None
            }
            logger.debug("[H-PROGRESS][start] version=1 steps=%s", [(s['key'], s['status']) for s in self._progress['steps']])

    def _update_progress_step(self, key: str, status: str = "running", message: str | None = None):
        with self._progress_lock:
            if not self._progress.get("active"):
                return
            steps = self._progress.get("steps", [])
            if status == "running" and self._progress.get("current") and self._progress["current"] != key:
                for s in steps:
                    if s["key"] == self._progress["current"] and s["status"] == "running":
                        s["status"] = "success"
                        s["finished_at"] = self._now_iso()
                        break
            for s in steps:
                if s["key"] == key:
                    if status == "error":
                        s["status"] = "error"
                        s["error_message"] = message or "Error"
                        s["finished_at"] = self._now_iso()
                        self._progress["error"] = s.get("error_message")
                        self._progress["current"] = None
                    elif status == "running":
                        if s["status"] in ("pending", "running"):
                            s["status"] = "running"
                            s.setdefault("started_at", self._now_iso())
                            self._progress["current"] = key
                    elif status == "success":
                        if s["status"] != "success":
                            s["status"] = "success"
                            s["finished_at"] = self._now_iso()
                            if self._progress.get("current") == key:
                                self._progress["current"] = None
                    break
            self._progress["updated_at"] = self._now_iso()
            self._progress["version"] = self._progress.get("version", 0) + 1
            try:
                logger.debug("[H-PROGRESS][update] step=%s status=%s version=%s snapshot=%s", key, status, self._progress['version'], [(s['key'], s['status']) for s in steps])
            except Exception:
                pass

    def _finish_progress(self, success: bool):
        with self._progress_lock:
            if not self._progress.get("active"):
                return
            if self._progress.get("current"):
                for s in self._progress["steps"]:
                    if s["key"] == self._progress["current"] and s["status"] == "running":
                        s["status"] = "success" if success else "error"
                        s["finished_at"] = self._now_iso()
                        break
            for s in self._progress["steps"]:
                if s["key"] == "complete" and s["status"] in ("pending", "running"):
                    s["status"] = "success" if success and not self._progress.get("error") else "error"
                    s["finished_at"] = self._now_iso()
                    break
            self._progress["active"] = False
            self._progress["finished_at"] = self._now_iso()
            self._progress["current"] = None
            self._progress["updated_at"] = self._now_iso()
            self._progress["version"] = self._progress.get("version", 0) + 1
            try:
                logger.debug("[H-PROGRESS][finish] success=%s version=%s steps=%s", success, self._progress['version'], [(s['key'], s['status']) for s in self._progress['steps']])
            except Exception:
                pass

    def get_progress(self) -> dict:
        with self._progress_lock:
            prog = self._progress.copy()
            prog["steps"] = [s.copy() for s in prog.get("steps", [])]
            return prog
        
    @property
    def classic_scraper(self):
        """Obtener scraper cl√°sico (lazy initialization)"""
        if self._classic_scraper is None:
            logger.info("üîÑ Inicializando scraper cl√°sico...")
            self._classic_scraper = LotteryMonitorScraper()
        return self._classic_scraper
    
    @property
    def intelligent_scraper(self):
        """Obtener scraper inteligente (lazy initialization)"""
        if not INTELLIGENT_SYSTEM_AVAILABLE:
            return None
            
        if self._intelligent_scraper is None:
            logger.info("üß† Inicializando scraper inteligente...")
            self._intelligent_scraper = IntelligentLotteryMonitorScraper()
        return self._intelligent_scraper
    
    def cleanup_scrapers(self):
        """Limpiar scrapers activos de forma segura"""
        try:
            if self._classic_scraper is not None:
                if hasattr(self._classic_scraper, 'cleanup_safe'):
                    self._classic_scraper.cleanup_safe()
                elif hasattr(self._classic_scraper, 'driver') and self._classic_scraper.driver:
                    try:
                        self._classic_scraper.driver.quit()
                    except:
                        pass
                logger.info("üîÑ Scraper cl√°sico cerrado")
                self._classic_scraper = None
                
            if self._intelligent_scraper is not None:
                if hasattr(self._intelligent_scraper, 'cleanup_safe'):
                    self._intelligent_scraper.cleanup_safe()
                elif hasattr(self._intelligent_scraper, 'driver') and self._intelligent_scraper.driver:
                    try:
                        self._intelligent_scraper.driver.quit()
                    except:
                        pass
                logger.info("üß† Scraper inteligente cerrado")
                self._intelligent_scraper = None
                
        except Exception as e:
            logger.warning(f"Error limpiando scrapers: {e}")
    
    def enable_intelligent_system(self, percentage: float = 100.0):
        """Habilitar sistema inteligente gradualmente"""
        if not INTELLIGENT_SYSTEM_AVAILABLE:
            logger.warning("Sistema inteligente no disponible")
            return False
            
        self.use_intelligent_system = True
        self.intelligent_percentage = min(100.0, max(0.0, percentage))
        self.intelligence_enabled = True
        
        logger.info(f"üß† Sistema inteligente habilitado al {self.intelligent_percentage}%")
        return True
    
    def disable_intelligent_system(self):
        """Deshabilitar sistema inteligente"""
        self.use_intelligent_system = False
        self.intelligent_percentage = 0
        self.intelligence_enabled = False
        logger.info("üîÑ Volviendo al sistema cl√°sico")
    
    def enable_comparison_mode(self):
        """Habilitar modo comparaci√≥n (ejecutar ambos sistemas)"""
        if not INTELLIGENT_SYSTEM_AVAILABLE:
            return False
            
        self.comparison_mode = True
        logger.info("‚öñÔ∏è  Modo comparaci√≥n habilitado")
        return True
    
    def disable_comparison_mode(self):
        """Deshabilitar modo comparaci√≥n"""
        self.comparison_mode = False
        logger.info("‚öñÔ∏è  Modo comparaci√≥n deshabilitado")
    
    def update_settings(self, settings_dict: dict) -> bool:
        """Actualizar configuraci√≥n de monitorizaci√≥n y umbrales en caliente en modo h√≠brido"""
        try:
            # Actualizar intervalo de monitoreo
            interval = settings_dict.get('monitoringInterval')
            if interval:
                from apscheduler.triggers.interval import IntervalTrigger
                Config.MONITORING_INTERVAL = interval
                job = self.scheduler.get_job('monitoring_job')
                if job:
                    job.reschedule(trigger=IntervalTrigger(minutes=interval))
                logger.info(f"Intervalo de monitoreo actualizado a {interval} minutos (h√≠brido)")
            # Actualizar umbrales de alerta
            Config.ALERT_THRESHOLDS['sales_threshold'] = settings_dict.get('salesThreshold', Config.ALERT_THRESHOLDS['sales_threshold'])
            Config.ALERT_THRESHOLDS['balance_threshold'] = settings_dict.get('balanceThreshold', Config.ALERT_THRESHOLDS['balance_threshold'])
            Config.ALERT_THRESHOLDS['growth_variation'] = settings_dict.get('growthVariation', Config.ALERT_THRESHOLDS['growth_variation'])
            Config.ALERT_THRESHOLDS['sustained_growth'] = settings_dict.get('sustainedGrowth', Config.ALERT_THRESHOLDS['sustained_growth'])
            # Actualizar headless y flags de filtros y alertas
            Config.HEADLESS_MODE = settings_dict.get('browserHeadless', Config.HEADLESS_MODE)
            Config.FILTER_SURIEL = settings_dict.get('filterSuriel', getattr(Config, 'FILTER_SURIEL', True))
            Config.FILTER_TOTAL_GENERAL = settings_dict.get('filterTotalGeneral', getattr(Config, 'FILTER_TOTAL_GENERAL', True))
            Config.ENABLE_GROWTH_ALERTS = settings_dict.get('enableGrowthAlerts', getattr(Config, 'ENABLE_GROWTH_ALERTS', True))
            Config.ENABLE_THRESHOLD_ALERTS = settings_dict.get('enableThresholdAlerts', getattr(Config, 'ENABLE_THRESHOLD_ALERTS', True))
            return True
        except Exception as e:
            logger.error(f"Error actualizando configuraci√≥n en HybridScheduler: {e}")
            return False

    def get_settings(self) -> dict:
        """Obtener configuraci√≥n actual del sistema h√≠brido"""
        try:
            return {
                'monitoringInterval': Config.MONITORING_INTERVAL,
                'browserHeadless': Config.HEADLESS_MODE,
                'filterSuriel': getattr(Config, 'FILTER_SURIEL', True),
                'filterTotalGeneral': getattr(Config, 'FILTER_TOTAL_GENERAL', True),
                'enableGrowthAlerts': getattr(Config, 'ENABLE_GROWTH_ALERTS', True),
                'enableThresholdAlerts': getattr(Config, 'ENABLE_THRESHOLD_ALERTS', True),
                'salesThreshold': Config.ALERT_THRESHOLDS.get('sales_threshold'),
                'balanceThreshold': Config.ALERT_THRESHOLDS.get('balance_threshold'),
                'growthVariation': Config.ALERT_THRESHOLDS.get('growth_variation'),
                'sustainedGrowth': Config.ALERT_THRESHOLDS.get('sustained_growth')
            }
        except Exception as e:
            logger.error(f"Error obteniendo configuraci√≥n en HybridScheduler: {e}")
            return {}
    
    def should_use_intelligent_system(self) -> bool:
        """Determinar si usar sistema inteligente en esta iteraci√≥n"""
        if not self.use_intelligent_system or not INTELLIGENT_SYSTEM_AVAILABLE:
            return False
        
        if self.intelligent_percentage >= 100:
            return True
        
        # Usar porcentaje para decidir
        import random
        return random.random() * 100 < self.intelligent_percentage
    
    def execute_iteration_classic(self) -> dict:
        """Ejecutar iteraci√≥n con sistema cl√°sico"""
        start_time = time.time()
        vision_activated = False
        
        try:
            logger.info("üîÑ Ejecutando iteraci√≥n cl√°sica...")
            # Iniciar progreso solo si no hay uno activo (permite inicio temprano desde manual)
            if not self._progress.get("active"):
                self._start_progress()
            self._update_progress_step("login", "running")
            
            # üîß INICIALIZACI√ìN LAZY DE SCRAPER CL√ÅSICO
            logger.info("üîÑ Inicializando scraper cl√°sico...")
            
            # ===== MONITOREO PREVENTIVO DE IRREGULARIDADES =====
            irregularities_detected = self._detect_pre_execution_irregularities()
            
            if irregularities_detected:
                logger.warning("üö® IRREGULARIDADES DETECTADAS - Activando visi√≥n preventiva...")
                vision_activated = self._activate_preventive_vision()
            
            # Ejecutar scraping cl√°sico con monitoreo en tiempo real
            # Pasar callback de progreso al scraper cl√°sico (lazy init asegurada)
            if self._classic_scraper is None:
                self._classic_scraper = LotteryMonitorScraper(progress_callback=self._update_progress_step)
            else:
                # Asegurar que el callback interno se actualiza cada iteraci√≥n
                try:
                    self._classic_scraper._progress_cb = self._update_progress_step
                except Exception:
                    pass
            scraped_data = self._execute_scraping_with_monitoring()
            
            if not scraped_data:
                logger.warning("No se obtuvieron datos del scraping cl√°sico")
                
                # üëÅÔ∏è ACTIVAR VISI√ìN DE EMERGENCIA si no se activ√≥ antes
                if not vision_activated:
                    logger.critical("üÜò ACTIVANDO VISI√ìN DE EMERGENCIA - Sin datos obtenidos")
                    self._activate_emergency_vision()
                
                self._update_progress_step("data_ready", "error", "Sin datos")
                self._finish_progress(False)
                return {
                    'success': False,
                    'method': 'classic',
                    'duration': time.time() - start_time,
                    'data_count': 0,
                    'error': 'No data obtained',
                    'vision_activated': vision_activated
                }
            
            # Procesar alertas  
            self._update_progress_step("data_ready", "success")
            self._update_progress_step("generate_alerts", "running")
            with SessionLocal() as db:
                alerts_generated = self.alert_system.process_agencies_data(scraped_data, db)
            self._update_progress_step("generate_alerts", "success")
            
            duration = time.time() - start_time
            self.performance_metrics['classic']['count'] += 1
            self.performance_metrics['classic']['total_time'] += duration
            
            logger.info(f"‚úÖ Iteraci√≥n cl√°sica completada: {len(scraped_data)} agencias, {len(alerts_generated)} alertas en {duration:.2f}s")
            
            self._finish_progress(True)
            return {
                'success': True,
                'method': 'classic',
                'duration': duration,
                'data_count': len(scraped_data),
                'alerts_count': len(alerts_generated),
                'data': scraped_data,
                'vision_activated': vision_activated
            }
            
        except Exception as e:
            duration = time.time() - start_time
            self.performance_metrics['classic']['errors'] += 1
            logger.error(f"‚ùå Error en iteraci√≥n cl√°sica: {e}")
            
            # üëÅÔ∏è ACTIVAR VISI√ìN DE EMERGENCIA en caso de error
            if not vision_activated:
                logger.critical("üÜò ACTIVANDO VISI√ìN DE EMERGENCIA - Error detectado")
                self._activate_emergency_vision()
            
            self._update_progress_step("complete", "error", str(e))
            self._finish_progress(False)
            return {
                'success': False,
                'method': 'classic', 
                'duration': duration,
                'error': str(e),
                'vision_activated': vision_activated
            }
    
    def _detect_pre_execution_irregularities(self) -> bool:
        """üîç Detectar irregularidades ANTES de ejecutar scraping"""
        try:
            # 1. Verificar uso an√≥malo de CPU/memoria
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            if cpu_percent > 80 or memory_percent > 85:
                logger.warning(f"üö® Recursos del sistema elevados: CPU {cpu_percent}%, RAM {memory_percent}%")
                return True
            
            # 2. Verificar historial de fallos recientes
            recent_failures = self._check_recent_failures()
            if recent_failures > 2:
                logger.warning(f"üö® {recent_failures} fallos recientes detectados")
                return True
                
            # 3. Verificar lentitud en iteraciones anteriores usando DOM Learning
            try:
                from .dom_learning_engine import dom_learner
                historical_performance = dom_learner.get_recent_performance_trend()
                
                if historical_performance.get('declining_performance', False):
                    logger.warning("üö® Rendimiento declinante detectado en iteraciones recientes")
                    return True
                    
                if historical_performance.get('anomalous_duration', False):
                    logger.warning("üö® Duraci√≥n an√≥mala detectada en an√°lisis DOM")
                    return True
                    
            except Exception as e:
                logger.debug(f"No se pudo verificar rendimiento DOM: {e}")
            
            return False
            
        except Exception as e:
            logger.error(f"Error detectando irregularidades: {e}")
            return False
    
    def _check_recent_failures(self) -> int:
        """Verificar fallos recientes en base de datos"""
        try:
            with SessionLocal() as db:
                from datetime import datetime, timedelta
                recent_time = datetime.now() - timedelta(hours=2)
                
                failures = db.query(SystemLog).filter(
                    SystemLog.timestamp >= recent_time,
                    SystemLog.level == 'ERROR'
                ).count()
                
                return failures
        except Exception:
            return 0
    
    def _activate_preventive_vision(self) -> bool:
        """üëÅÔ∏è Activar sistema de visi√≥n preventiva"""
        try:
            logger.info("üëÅÔ∏è ACTIVANDO SISTEMA DE VISI√ìN PREVENTIVA...")
            
            # Verificar si el sistema de visi√≥n est√° disponible
            if not hasattr(self.classic_scraper, 'vision_engine'):
                logger.warning("‚ö†Ô∏è Sistema de visi√≥n no disponible en scraper cl√°sico")
                return False
            
            # Activar visi√≥n por tiempo limitado (30 segundos)
            vision_result = self.classic_scraper.vision_engine.activate_preventive_monitoring(duration=30)
            
            if vision_result['success']:
                logger.info(f"‚úÖ Visi√≥n preventiva activada: {vision_result['monitoring_type']}")
                
                # Log insights capturados
                insights = vision_result.get('insights', [])
                for insight in insights:
                    logger.info(f"üí° Insight visual: {insight}")
                
                return True
            else:
                logger.warning(f"‚ùå No se pudo activar visi√≥n preventiva: {vision_result.get('error', 'Unknown')}")
                return False
                
        except Exception as e:
            logger.error(f"Error activando visi√≥n preventiva: {e}")
            return False
    
    def _activate_emergency_vision(self):
        """üÜò Activar visi√≥n de emergencia cuando ya ocurri√≥ el fallo"""
        try:
            logger.critical("üÜò ACTIVANDO VISI√ìN DE EMERGENCIA...")
            
            # Verificar si tenemos sistema de visi√≥n disponible
            if not hasattr(self.classic_scraper, 'vision_engine') or not self.classic_scraper.vision_engine:
                logger.error("‚ö†Ô∏è Sistema de visi√≥n no disponible para emergencia")
                return
            
            # Verificar si el driver est√° activo antes de capturar
            driver_available = False
            try:
                if hasattr(self.classic_scraper, 'driver') and self.classic_scraper.driver:
                    # Verificar si el driver est√° realmente activo
                    _ = self.classic_scraper.driver.title
                    driver_available = True
            except Exception as e:
                logger.warning(f"Driver no disponible para visi√≥n de emergencia: {e}")
                driver_available = False
            
            if not driver_available:
                logger.critical("üì∏ Estado de emergencia capturado: Screenshot FALL√ì - Driver no disponible")
                
                # Registrar el fallo sin intentar captura
                with SessionLocal() as db:
                    emergency_log = SystemLog(
                        level='CRITICAL',
                        message="Visi√≥n de emergencia: Driver no disponible para captura - Sistema en estado cr√≠tico",
                        module='scheduler_hybrid',
                        timestamp=datetime.now()
                    )
                    db.add(emergency_log)
                    db.commit()
                return
            
            # Capturar estado visual actual para diagn√≥stico
            emergency_result = self.classic_scraper.vision_engine.capture_emergency_state()
            
            if emergency_result['success']:
                logger.critical(f"üì∏ Estado de emergencia capturado: {emergency_result['state_description']}")
                
                # Guardar evidencia del fallo
                with SessionLocal() as db:
                    emergency_log = SystemLog(
                        level='CRITICAL',
                        message=f"Visi√≥n de emergencia: {emergency_result['state_description']} - Detalles: {str(emergency_result)}",
                        module='scheduler_hybrid',
                        timestamp=datetime.now()
                    )
                    db.add(emergency_log)
                    db.commit()
                    
                # Intentar diagn√≥stico autom√°tico
                diagnosis = emergency_result.get('auto_diagnosis', {})
                if diagnosis:
                    logger.critical(f"üî¨ Diagn√≥stico autom√°tico: {diagnosis.get('probable_cause', 'Desconocido')}")
                    logger.critical(f"üí° Recomendaci√≥n: {diagnosis.get('recommendation', 'Reiniciar sistema')}")
            else:
                logger.critical(f"üì∏ Estado de emergencia capturado: Screenshot FALL√ì - {emergency_result.get('error', 'Error desconocido')}")
            
        except Exception as e:
            logger.error(f"Error en visi√≥n de emergencia: {e}")
    
    def _execute_scraping_with_monitoring(self):
        """Ejecutar scraping con monitoreo continuo de irregularidades"""
        try:
            # Verificar si hay se√±ales de problema cada 10 segundos durante el scraping
            import threading
            import time
            
            monitoring_active = True
            vision_triggered = False
            
            def monitor_during_scraping():
                nonlocal monitoring_active, vision_triggered
                while monitoring_active:
                    time.sleep(10)  # Verificar cada 10 segundos
                    
                    if not monitoring_active:
                        break
                        
                    # Verificar se√±ales de problemas durante ejecuci√≥n
                    cpu_percent = psutil.cpu_percent()
                    if cpu_percent > 90 and not vision_triggered:
                        logger.warning("üö® CPU cr√≠tico durante scraping - Activando visi√≥n")
                        self._activate_preventive_vision()
                        vision_triggered = True
            
            # Iniciar monitoreo en hilo separado
            monitor_thread = threading.Thread(target=monitor_during_scraping, daemon=True)
            monitor_thread.start()
            
            try:
                # Ejecutar scraping normal
                scraped_data = self.classic_scraper.scrape_all_data()
                
                # Peque√±a pausa para permitir que el sistema de visi√≥n procese si es necesario
                time.sleep(2)
                
                return scraped_data
            finally:
                # Detener monitoreo
                monitoring_active = False
                
        except Exception as e:
            logger.error(f"Error en scraping con monitoreo: {e}")
            return self.classic_scraper.scrape_all_data()  # Fallback normal
    
    def execute_iteration_intelligent(self) -> dict:
        """Ejecutar iteraci√≥n con sistema inteligente"""
        start_time = time.time()
        try:
            logger.info("üß† Ejecutando iteraci√≥n inteligente...")
            if not self._progress.get("active"):
                self._start_progress()
            self._update_progress_step("login", "running")
            
            # Ejecutar scraping inteligente
            # Asegurar callback tambi√©n en inteligente
            if self._intelligent_scraper is None:
                self._intelligent_scraper = IntelligentLotteryMonitorScraper(progress_callback=self._update_progress_step) if INTELLIGENT_SYSTEM_AVAILABLE else None
            else:
                try:
                    self._intelligent_scraper._progress_cb = self._update_progress_step
                except Exception:
                    pass
            scraped_data = self.intelligent_scraper.scrape_all_data_intelligent()
            
            if not scraped_data:
                logger.warning("No se obtuvieron datos del scraping inteligente")
                self._update_progress_step("data_ready", "error", "Sin datos")
                self._finish_progress(False)
                return {
                    'success': False,
                    'method': 'intelligent',
                    'duration': time.time() - start_time,
                    'data_count': 0,
                    'error': 'No data obtained'
                }
            
            # Procesar alertas
            self._update_progress_step("data_ready", "success")
            self._update_progress_step("generate_alerts", "running")
            with SessionLocal() as db:
                alerts_generated = self.alert_system.process_agencies_data(scraped_data, db)
            self._update_progress_step("generate_alerts", "success")
            
            duration = time.time() - start_time
            self.performance_metrics['intelligent']['count'] += 1
            self.performance_metrics['intelligent']['total_time'] += duration
            
            logger.info(f"üß† Iteraci√≥n inteligente completada: {len(scraped_data)} agencias, {len(alerts_generated)} alertas en {duration:.2f}s")
            
            self._finish_progress(True)
            return {
                'success': True,
                'method': 'intelligent',
                'duration': duration,
                'data_count': len(scraped_data),
                'alerts_count': len(alerts_generated),
                'data': scraped_data,
                'intelligence_summary': self.intelligent_scraper.get_intelligence_summary() if self.intelligent_scraper else None
            }
            
        except Exception as e:
            duration = time.time() - start_time
            self.performance_metrics['intelligent']['errors'] += 1
            logger.error(f"‚ùå Error en iteraci√≥n inteligente: {e}")
            
            self._update_progress_step("complete", "error", str(e))
            self._finish_progress(False)
            return {
                'success': False,
                'method': 'intelligent',
                'duration': duration,
                'error': str(e)
            }
    
    def execute_comparison_iteration(self) -> dict:
        """Ejecutar ambos sistemas y comparar resultados"""
        logger.info("‚öñÔ∏è  Ejecutando iteraci√≥n comparativa...")
        
        classic_result = self.execute_iteration_classic()
        intelligent_result = self.execute_iteration_intelligent()
        
        # Analizar diferencias
        comparison = self.analyze_results_comparison(classic_result, intelligent_result)
        
        # Usar el resultado m√°s exitoso
        primary_result = intelligent_result if intelligent_result['success'] else classic_result
        
        return {
            **primary_result,
            'comparison_mode': True,
            'classic_result': classic_result,
            'intelligent_result': intelligent_result,
            'comparison_analysis': comparison
        }
    
    def analyze_results_comparison(self, classic_result: dict, intelligent_result: dict) -> dict:
        """Analizar diferencias entre resultados cl√°sicos e inteligentes"""
        try:
            analysis = {
                'both_successful': classic_result['success'] and intelligent_result['success'],
                'performance_difference': None,
                'data_difference': None,
                'recommendation': 'continue_testing'
            }
            
            if analysis['both_successful']:
                # Comparar rendimiento
                time_improvement = ((classic_result['duration'] - intelligent_result['duration']) / classic_result['duration']) * 100
                analysis['performance_difference'] = {
                    'classic_duration': classic_result['duration'],
                    'intelligent_duration': intelligent_result['duration'],
                    'improvement_percentage': time_improvement
                }
                
                # Comparar datos obtenidos
                analysis['data_difference'] = {
                    'classic_count': classic_result.get('data_count', 0),
                    'intelligent_count': intelligent_result.get('data_count', 0),
                    'data_consistency': abs(classic_result.get('data_count', 0) - intelligent_result.get('data_count', 0)) <= 2
                }
                
                # Generar recomendaci√≥n
                if time_improvement > 20 and analysis['data_difference']['data_consistency']:
                    analysis['recommendation'] = 'migrate_to_intelligent'
                elif time_improvement < -10:  # Sistema inteligente es m√°s lento
                    analysis['recommendation'] = 'stick_to_classic'
                else:
                    analysis['recommendation'] = 'continue_testing'
            
            return analysis
            
        except Exception as e:
            logger.error(f"Error analizando comparaci√≥n: {e}")
            return {'error': str(e)}
    
    def execute_single_iteration(self):
        """Ejecutar una sola iteraci√≥n (punto de entrada principal)"""
        logger.info("üîÑ INICIANDO ITERACI√ìN AUTOM√ÅTICA PROGRAMADA")
        try:
            if self.comparison_mode:
                logger.info("üîÑ Ejecutando en modo comparaci√≥n")
                result = self.execute_comparison_iteration()
            elif self.should_use_intelligent_system():
                logger.info("üîÑ Ejecutando iteraci√≥n inteligente")
                result = self.execute_iteration_intelligent()
            else:
                logger.info("üîÑ Ejecutando iteraci√≥n cl√°sica autom√°tica")
                result = self.execute_iteration_classic()
                
        except Exception as e:
            logger.error(f"‚ùå Error en ejecuci√≥n de iteraci√≥n autom√°tica: {e}")
            return {
                'success': False,
                'method': 'unknown',
                'error': str(e),
                'duration': 0
            }
        
        finally:
            # Limpiar estado al finalizar
            import os
            current_pid = os.getpid()
            logging.info(f"PID: {current_pid} - Proceso de monitoreo finalizado.")

        if result and result.get("status") == "success":
            return {"status": "completed", "message": "Monitoreo finalizado con √©xito", "data": result}
        else:
            return {"status": "failed", "message": "Monitoreo finalizado con errores", "data": result}

    def enable_continuous_mode(self, delay_seconds: int = 10):
        """üöÄ Activar modo continuo de ejecuci√≥n (para pruebas)"""
        self.continuous_mode = True
        self.continuous_delay = delay_seconds
        logger.info(f"üöÄ MODO CONTINUO ACTIVADO: {delay_seconds}s entre ejecuciones")
        return {
            'success': True,
            'message': f'Modo continuo activado con {delay_seconds}s de delay',
            'continuous_mode': True,
            'delay_seconds': delay_seconds
        }
    
    def disable_continuous_mode(self):
        """üõë Desactivar modo continuo de ejecuci√≥n"""
        self.continuous_mode = False
        # Cancelar job continuo si existe
        try:
            self.scheduler.remove_job('continuous_iteration')
            logger.info("üöÄ Job continuo cancelado")
        except:
            pass
        logger.info("üõë MODO CONTINUO DESACTIVADO")
        return {
            'success': True,
            'message': 'Modo continuo desactivado',
            'continuous_mode': False
        }
    
    def execute_manual_iteration(self):
        """üîÑ Ejecutar una iteraci√≥n manual de monitoreo"""
        try:
            logger.info("üîÑ Iniciando iteraci√≥n manual as√≠ncrona (no bloqueante)...")
            if self._progress.get("active"):
                return {
                    'success': False,
                    'message': 'Ya hay una iteraci√≥n en progreso',
                    'result': None
                }
            # Inicio temprano de progreso
            self._start_progress()
            self._update_progress_step("login", "running")
            import threading
            def _run():
                try:
                    self.execute_single_iteration()
                except Exception as e:
                    logger.exception("Error en hilo de iteraci√≥n manual: %s", e)
                    self._update_progress_step("complete", "error", str(e))
                    self._finish_progress(False)
            threading.Thread(target=_run, daemon=True).start()
            return {
                'success': True,
                'message': 'Iteraci√≥n manual lanzada',
                'result': None
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error en iteraci√≥n manual: {e}")
            return {
                'success': False,
                'message': f'Error en iteraci√≥n manual: {str(e)}',
                'result': None
            }
    
    def _update_monitoring_interval(self, interval: int):
        """Actualizar intervalo de monitoreo"""
        try:
            # Actualizar configuraci√≥n local
            Config.MONITORING_INTERVAL = interval
            
            # Si hay un job activo, reagendarlo
            if self.is_running:
                job = self.scheduler.get_job('monitoring_job')
                if job:
                    from apscheduler.triggers.interval import IntervalTrigger
                    job.reschedule(trigger=IntervalTrigger(minutes=interval))
                    logger.info(f"Intervalo de monitoreo actualizado a {interval} minutos")
            
            return True
        except Exception as e:
            logger.error(f"Error actualizando intervalo: {e}")
            return False
    
    def _update_sales_threshold(self, threshold: float):
        """Actualizar umbral de ventas"""
        try:
            Config.ALERT_THRESHOLDS['sales_threshold'] = threshold
            logger.info(f"Umbral de ventas actualizado a {threshold}")
            return True
        except Exception as e:
            logger.error(f"Error actualizando umbral de ventas: {e}")
            return False
    
    def _update_wait_time(self, wait_type: str, wait_time: float):
        """Actualizar tiempos de espera"""
        try:
            if wait_type == "page_load":
                Config.WAIT_TIME_PAGE_LOAD = wait_time
            elif wait_type == "element":
                Config.WAIT_TIME_ELEMENT = wait_time
            else:
                logger.warning(f"Tipo de wait_time desconocido: {wait_type}")
                return False
            
            logger.info(f"Tiempo de espera {wait_type} actualizado a {wait_time}s")
            return True
        except Exception as e:
            logger.error(f"Error actualizando wait_time: {e}")
            return False
    
    def _schedule_continuous_iteration(self):
        """üîÑ M√©todo helper para programar iteraci√≥n continua (usado en reintentos)"""
        try:
            from datetime import timedelta
            next_run_time = datetime.now() + timedelta(seconds=self.continuous_delay)
            logger.info(f"üîÑ Reintentando programaci√≥n continua para: {next_run_time.strftime('%H:%M:%S')}")
            
            self.scheduler.add_job(
                self.execute_single_iteration,
                'date',
                run_date=next_run_time,
                id='continuous_iteration',
                replace_existing=True
            )
            logger.info("‚úÖ Iteraci√≥n continua reprogramada exitosamente")
            
        except Exception as e:
            logger.error(f"‚ùå Fallo en reprogramaci√≥n continua: {e}")
    
    def get_status(self):
        """Obtener estado del scheduler"""
        status = {
            'is_running': self.is_running,
            'monitoring_interval': Config.MONITORING_INTERVAL,
            'use_intelligent_system': self.use_intelligent_system,
            'intelligent_percentage': self.intelligent_percentage,
            'comparison_mode': self.comparison_mode,
            'intelligent_system_available': INTELLIGENT_SYSTEM_AVAILABLE,
            # 'performance_metrics': self.get_performance_comparison(),
            # üöÄ Estado del modo continuo
            'continuous_mode': self.continuous_mode,
            'continuous_delay': self.continuous_delay if self.continuous_mode else None
        }
        
        # Agregar tiempo de pr√≥xima ejecuci√≥n del job de monitoreo
        try:
            job = self.scheduler.get_job('monitoring_job')
            if job and job.next_run_time:
                status['next_run_time'] = job.next_run_time.isoformat()
        except Exception:
            pass
        
        # Agregar tiempo de pr√≥xima ejecuci√≥n continua si existe
        try:
            continuous_job = self.scheduler.get_job('continuous_iteration')
            if continuous_job and continuous_job.next_run_time:
                status['next_continuous_run'] = continuous_job.next_run_time.isoformat()
        except Exception:
            pass
            
        return status
    
    def get_intelligence_status(self):
        """Obtener estado completo del sistema de inteligencia"""
        if not INTELLIGENT_SYSTEM_AVAILABLE:
            return {
                'intelligence_enabled': False,
                'error': 'Sistema inteligente no disponible'
            }
            
        try:
            adaptive_config = intelligence_engine.get_adaptive_config() if hasattr(intelligence_engine, 'get_adaptive_config') else {}
            failure_prediction = intelligence_engine.predict_failure_risk({'current_hour': datetime.now().hour}) if hasattr(intelligence_engine, 'predict_failure_risk') else None
            
            return {
                'intelligence_enabled': self.intelligence_enabled,
                'adaptive_config': adaptive_config,
                'failure_prediction': failure_prediction,
                'system_metrics': {
                    'prediction_accuracy': 0.85,  # Placeholder
                    'optimizations_applied': len(dom_intelligence.optimizer.current_optimizations) if dom_intelligence else 0
                },
                'anomalies_detected': 0,  # Placeholder
                'optimizations_available': len(adaptive_config) if adaptive_config else 0
            }
            
        except Exception as e:
            logger.error(f"Error obteniendo estado de inteligencia: {e}")
            return {
                'intelligence_enabled': self.intelligence_enabled,
                'error': str(e)
            }
    
    def toggle_intelligence(self, enabled: bool):
        """Activar/desactivar sistema de inteligencia"""
        if enabled:
            return self.enable_intelligent_system()
        else:
            self.disable_intelligent_system()
            return True
    
    def start_monitoring(self) -> bool:
        """Iniciar el monitoreo autom√°tico"""
        try:
            if self.is_running:
                logger.warning("El monitoreo ya est√° en ejecuci√≥n")
                return False
            
            # Crear nueva sesi√≥n de monitoreo
            db = SessionLocal()
            session = MonitoringSession(
                session_date=date.today().isoformat(),
                status="active"
            )
            db.add(session)
            db.commit()
            self.current_session_id = session.id
            db.close()
            
            # Configurar tarea programada
            self.scheduler.add_job(
                func=self.execute_single_iteration,
                trigger=IntervalTrigger(minutes=Config.MONITORING_INTERVAL),
                id='monitoring_job',
                replace_existing=True
            )
            
            # Iniciar el scheduler
            if not self.scheduler.running:
                self.scheduler.start()
            
            self.is_running = True
            logger.info(f"‚úÖ Monitoreo h√≠brido iniciado (intervalo: {Config.MONITORING_INTERVAL} min)")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error iniciando monitoreo: {e}")
            return False
    
    def stop_monitoring(self) -> bool:
        """Detener el monitoreo autom√°tico"""
        try:
            if not self.is_running:
                logger.warning("El monitoreo no est√° en ejecuci√≥n")
                return False
            
            # Remover el job de monitoreo
            try:
                self.scheduler.remove_job('monitoring_job')
            except Exception:
                pass
            
            # Actualizar sesi√≥n actual como completada
            if self.current_session_id:
                db = SessionLocal()
                session = db.query(MonitoringSession).filter(
                    MonitoringSession.id == self.current_session_id
                ).first()
                if session:
                    session.status = "completed"
                    db.commit()
                db.close()
            
            self.is_running = False
            logger.info("‚èπÔ∏è Monitoreo h√≠brido detenido")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error deteniendo monitoreo: {e}")
            return False

# Crear instancia global del scheduler h√≠brido
monitoring_scheduler = HybridMonitoringScheduler()

# Alias para compatibilidad
MonitoringScheduler = HybridMonitoringScheduler
